{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Preparing Source Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyodbc\n",
    "%pip install elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the environment ready, use the following Python code to create a SQL Server database (PersonSearchDB), setting up a Persons table, and populating it with 1 million realistic random records (first names, last names, cities, states, and email addresses using randommail.com for privacy). After testing, a cleanup script can safely remove the database and table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import random\n",
    "import datetime\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "# Define server name as a global variable so it can be set once\n",
    "server = 'localhost'\n",
    "db_name = 'PersonSearchDB'\n",
    "\n",
    "# Connection to 'master' for creating the database\n",
    "master_conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE=master;Trusted_Connection=yes;'\n",
    "master_conn = pyodbc.connect(master_conn_str)\n",
    "\n",
    "# Set autocommit to True to disable transactions\n",
    "master_conn.autocommit = True\n",
    "\n",
    "master_cursor = master_conn.cursor()\n",
    "\n",
    "# Check if the database exists, if not, create it\n",
    "create_db_query = f\"IF DB_ID('{db_name}') IS NULL CREATE DATABASE {db_name};\"\n",
    "master_cursor.execute(create_db_query)\n",
    "\n",
    "# Close master connection\n",
    "master_cursor.close()\n",
    "master_conn.close()\n",
    "\n",
    "# Function to return SQL Server connection\n",
    "def get_sql_connection(db_name):\n",
    "    \"\"\"\n",
    "    Returns a SQL Server connection object for the given database name.\n",
    "    If the database does not exist, the function connects to 'master' first to create it.\n",
    "    \n",
    "    Parameters:\n",
    "    db_name (str): The name of the database to connect to.\n",
    "\n",
    "    Returns:\n",
    "    pyodbc.Connection: A connection object to the specified database.\n",
    "    \"\"\"    \n",
    "\n",
    "    # Connection to the newly created or existing database\n",
    "    conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={db_name};Trusted_Connection=yes;'\n",
    "    return pyodbc.connect(conn_str)\n",
    "\n",
    "# Function to execute a SQL query\n",
    "def execute_SQL_Query(db_name, query, params=None):\n",
    "    \"\"\"\n",
    "    Executes a SQL query on the given database. Uses the connection obtained from get_sql_connection.\n",
    "    \n",
    "    Parameters:\n",
    "    db_name (str): The name of the database.\n",
    "    query (str): The SQL query to execute.\n",
    "    params (tuple): Parameters to pass to the query (optional).\n",
    "    \n",
    "    Returns:\n",
    "    list: The result of the query if it's a SELECT query, otherwise None.\n",
    "    \"\"\"\n",
    "    conn = get_sql_connection(db_name)\n",
    "    cursor = conn.cursor()\n",
    "    if params:\n",
    "        cursor.execute(query, params)\n",
    "    else:\n",
    "        cursor.execute(query)\n",
    "    \n",
    "    if query.strip().upper().startswith(\"SELECT\"):\n",
    "        result = cursor.fetchall()  # Fetch all results if it's a SELECT query\n",
    "    else:\n",
    "        conn.commit()\n",
    "        result = None\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "# Create database\n",
    "execute_SQL_Query('master', f\"IF DB_ID('{db_name}') IS NULL CREATE DATABASE {db_name};\")\n",
    "\n",
    "# List of Indian first names, last names, cities, and states\n",
    "first_names = ['Rahul', 'Anjali', 'Amit', 'Pooja', 'Rajesh', 'Sneha', 'Vikram', 'Neha', 'Suresh', 'Sunita']\n",
    "last_names = ['Sharma', 'Patel', 'Gupta', 'Mehta', 'Jain', 'Agarwal', 'Reddy', 'Singh', 'Kumar', 'Verma']\n",
    "cities = ['Mumbai', 'Delhi', 'Bangalore', 'Chennai', 'Hyderabad', 'Ahmedabad', 'Kolkata', 'Pune', 'Jaipur', 'Lucknow']\n",
    "states = ['MH', 'DL', 'KA', 'TN', 'TS', 'GJ', 'WB', 'MH', 'RJ', 'UP']\n",
    "\n",
    "def random_name():\n",
    "    return random.choice(first_names), random.choice(last_names)\n",
    "\n",
    "def random_email(first_name, last_name):\n",
    "    return f\"{first_name.lower()}.{last_name.lower()}@randommail.com\"\n",
    "\n",
    "def random_DOB():\n",
    "    start_date = datetime.date(1950, 1, 1)\n",
    "    end_date = datetime.date(2005, 12, 31)\n",
    "    time_between_dates = end_date - start_date\n",
    "    days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange(days_between_dates)\n",
    "    random_date = start_date + datetime.timedelta(days=random_number_of_days)\n",
    "    return random_date\n",
    "\n",
    "def random_zipcode():\n",
    "    return str(random.randint(100000, 999999))  # Indian zip codes are 6 digits\n",
    "\n",
    "# Function to create the table and insert records in bulk\n",
    "def setup_database_and_bulk_insert_data(db_name, record_count=1000, batch_size=100):\n",
    "    # Create Persons table using execute_SQL_Query\n",
    "    create_table_query = '''\n",
    "    IF OBJECT_ID('Persons', 'U') IS NOT NULL DROP TABLE Persons;\n",
    "    CREATE TABLE Persons (\n",
    "        FirstName NVARCHAR(50),\n",
    "        LastName NVARCHAR(50),\n",
    "        PreferredName NVARCHAR(50),\n",
    "        City NVARCHAR(50),\n",
    "        State NVARCHAR(50),\n",
    "        ZipCode NVARCHAR(10),\n",
    "        DOB DATE,\n",
    "        Email NVARCHAR(100)\n",
    "    );\n",
    "    '''\n",
    "    execute_SQL_Query(db_name, create_table_query)\n",
    "\n",
    "    # Insert records in batches\n",
    "    for batch_start in range(0, record_count, batch_size):\n",
    "        values = []\n",
    "        for _ in range(batch_size):\n",
    "            first_name, last_name = random_name()\n",
    "            preferred_name = first_name  # Assume preferred name is the first name\n",
    "            city = random.choice(cities)\n",
    "            state = random.choice(states)\n",
    "            zipcode = random_zipcode()\n",
    "            dob = random_DOB()\n",
    "            dob_str = dob.strftime('%Y-%m-%d')\n",
    "            email = random_email(first_name, last_name)\n",
    "            values.append(f\"SELECT '{first_name}', '{last_name}', '{preferred_name}', '{city}', '{state}', '{zipcode}', '{dob_str}', '{email}'\")\n",
    "\n",
    "        # Create bulk insert query using INSERT INTO ... SELECT\n",
    "        insert_query = '''\n",
    "        INSERT INTO Persons (FirstName, LastName, PreferredName, City, State, ZipCode, DOB, Email)\n",
    "        ''' + \" UNION ALL \".join(values)\n",
    "\n",
    "        execute_SQL_Query(db_name, insert_query)\n",
    "        print(f\"Inserted batch starting at record {batch_start}\")\n",
    "\n",
    "# Example usage: setting up the database and bulk inserting data\n",
    "setup_database_and_bulk_insert_data(db_name, record_count=1000, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Setting Up Elasticsearch\n",
    "\n",
    "    • Download and Install: Obtain Elasticsearch from the official website and follow the installation guide.\n",
    "    • Configuration: Adjust settings as needed, such as cluster name and network configurations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Creating an Elasticsearch Index\n",
    "    • Define Mappings: Specify how each field should be indexed and analyzed, particularly those requiring fuzzy search capabilities.\n",
    "\n",
    "    • Index Creation: Use Python scripts or tools like Kibana to create the index with the defined mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "import warnings\n",
    "import urllib3\n",
    "\n",
    "# Suppress warnings about insecure connections (optional)\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "   \n",
    "# Replace with your actual password\n",
    "elastic_password = \"IMoWOv8DHTMNnQod37NS\"\n",
    "\n",
    "# Initialize the Elasticsearch client with SSL and authentication\n",
    "# make sure elastic search is running on port 9200, \n",
    "# Use the following command to start elastic search\n",
    "# .\\elasticsearch-8.11.1\\bin\\elasticsearch.bat\n",
    "\n",
    "\n",
    "es = Elasticsearch(\n",
    "    [\"https://localhost:9200\"],\n",
    "    ca_certs=False,          # Disable SSL certificate verification\n",
    "    verify_certs=False,      # Disable SSL cert verification (use with caution)\n",
    "    basic_auth=(\"elastic\", elastic_password),\n",
    ")\n",
    "\n",
    "def index_data_to_elasticsearch(db_name, index_name, batch_size=10000):\n",
    "    \n",
    "    # Delete the existing index if it exists\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "        print(f\"Deleted existing index: {index_name}\")\n",
    "\n",
    "    # Create a new index with mappings\n",
    "    index_mappings = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"FirstName\": {\"type\": \"text\"},\n",
    "                \"LastName\": {\"type\": \"text\"},\n",
    "                \"PreferredName\": {\"type\": \"text\"},\n",
    "                \"City\": {\"type\": \"text\"},\n",
    "                \"State\": {\"type\": \"keyword\"},\n",
    "                \"ZipCode\": {\"type\": \"keyword\"},\n",
    "                \"DOB\": {\"type\": \"date\"},\n",
    "                \"Email\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=index_name, body=index_mappings)\n",
    "    print(f\"Created new index: {index_name}\")\n",
    "\n",
    "    # Get total number of records\n",
    "    total_records_query = \"SELECT COUNT(*) FROM Persons\"\n",
    "    total_records_result = execute_SQL_Query(db_name, total_records_query)\n",
    "    total_records = total_records_result[0][0]\n",
    "\n",
    "    offset = 0\n",
    "    while offset < total_records:\n",
    "        query = f'''\n",
    "        SELECT FirstName, LastName, PreferredName, City, State, ZipCode, DOB, Email\n",
    "        FROM Persons\n",
    "        ORDER BY FirstName\n",
    "        OFFSET {offset} ROWS FETCH NEXT {batch_size} ROWS ONLY\n",
    "        '''\n",
    "        rows = execute_SQL_Query(db_name, query)\n",
    "        actions = []\n",
    "        for row in rows:\n",
    "            print(f\"\\n\\nrow: {row}\")\n",
    "            doc = {\n",
    "                \"_index\": index_name,\n",
    "                \"_source\": {\n",
    "                    \"FirstName\": row[0],\n",
    "                    \"LastName\": row[1],\n",
    "                    \"PreferredName\": row[2],\n",
    "                    \"City\": row[3],\n",
    "                    \"State\": row[4],\n",
    "                    \"ZipCode\": row[5],\n",
    "                    \"DOB\": row[6].strftime('%Y-%m-%d') if row[6] else None,\n",
    "                    \"Email\": row[7]\n",
    "                }\n",
    "            }\n",
    "            actions.append(doc)\n",
    "            \n",
    "        try:\n",
    "            helpers.bulk(es, actions)\n",
    "        except helpers.BulkIndexError as e:\n",
    "            print(f\"Bulk indexing error: {e}\")\n",
    "            for error in e.errors:\n",
    "                print(error)\n",
    "        \n",
    "        offset += batch_size\n",
    "        print(f\"Indexed {offset}/{total_records} records\")\n",
    "\n",
    "# Example usage: setting up the database and bulk inserting data\n",
    "# setup_database_and_bulk_insert_data(db_name, record_count=1000, batch_size=100)\n",
    "index_data_to_elasticsearch('PersonSearchDB', 'person_index', batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
